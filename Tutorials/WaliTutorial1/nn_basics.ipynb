{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install tensorflow.keras\n",
    "%pip install tensorflow.keras.\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('input/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.shape #shows dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "credit_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.describe() #shows statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit_data.iloc[:,:30]\n",
    "y = credit_data.iloc[:,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    tfl.Input(shape = (30,)), #input layer with 30 features\n",
    "    tfl.Dense(256,activation = 'sigmoid'), \n",
    "    tfl.Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m7,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> (32.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,193\u001b[0m (32.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> (32.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,193\u001b[0m (32.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        tfl.Input(shape=(30,)),\n",
    "        tfl.Dense(units = 512, activation = 'sigmoid'),\n",
    "        tfl.Dense(units = 512, activation = 'sigmoid'),\n",
    "        tfl.Dense(units = 1, activation = 'sigmoid'),\n",
    "         #compile the model\n",
    "    ])\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m15,872\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">279,041</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m279,041\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">279,041</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m279,041\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0158\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs = 1) #train the model for 1 round with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_mask = credit_data['Class'] == 1 #mask to filter fraud cases\n",
    "\n",
    "fraud_data = credit_data[fraud_mask] #filter the data to only include fraud cases\n",
    "\n",
    "X_fraud = fraud_data.iloc[:,:30]\n",
    "y_fraud = fraud_data.iloc[:,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fraud.shape #shows the shape of the fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 6.8462 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.84614896774292, 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_fraud, y_fraud) #evaluate the model on the fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00106355],\n",
       "       [0.00106259],\n",
       "       [0.00106351],\n",
       "       [0.00106355],\n",
       "       [0.00106355],\n",
       "       [0.00106355],\n",
       "       [0.00106355],\n",
       "       [0.00106355],\n",
       "       [0.00106355],\n",
       "       [0.00106355]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_fraud[:10]) #predict the first 10 rows of the fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_totals = [len(y)-len(y_fraud),len(y_fraud)]\n",
    "class_weight = {i:len(y)/(2*total) for i, total in enumerate(class_totals)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = keras.metrics.AUC(curve = 'PR')\n",
    "\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        tfl.Input(shape=(30,)),\n",
    "        tfl.Dense(units = 64, activation = 'relu'),\n",
    "        tfl.Dense(units = 64, activation = 'relu'),\n",
    "        tfl.Dense(units = 1, activation = 'sigmoid'),\n",
    "    ])\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy',AUC])\n",
    "    return model #use better metric AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,209</span> (24.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,209\u001b[0m (24.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,209</span> (24.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,209\u001b[0m (24.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 748us/step - accuracy: 0.5285 - auc: 0.0017 - loss: 1087.4905\n",
      "Epoch 2/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 746us/step - accuracy: 0.5453 - auc: 0.0019 - loss: 62.6596\n",
      "Epoch 3/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 753us/step - accuracy: 0.7175 - auc: 0.0056 - loss: 1.1559\n",
      "Epoch 4/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 751us/step - accuracy: 0.6091 - auc: 0.0015 - loss: 0.8133\n",
      "Epoch 5/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 768us/step - accuracy: 0.1760 - auc: 0.0016 - loss: 2.6307\n",
      "Epoch 6/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 754us/step - accuracy: 0.1189 - auc: 0.0039 - loss: 0.7122\n",
      "Epoch 7/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 756us/step - accuracy: 0.5944 - auc: 0.0024 - loss: 0.9173\n",
      "Epoch 8/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 764us/step - accuracy: 0.8516 - auc: 0.0016 - loss: 1.3490\n",
      "Epoch 9/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 754us/step - accuracy: 0.0891 - auc: 0.0016 - loss: 0.9183\n",
      "Epoch 10/10\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 746us/step - accuracy: 0.4875 - auc: 0.0026 - loss: 1.1660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x186d7363e10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=10, class_weight = class_weight) #train the model for 10 rounds with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate):\n",
    "    model = keras.Sequential([\n",
    "        tfl.Input(shape=(30,)),\n",
    "        tfl.Dense(units = 128, activation = 'leaky_relu'),\n",
    "        tfl.Dense(units = 256, activation = 'leaky_relu'),\n",
    "        tfl.Dense(units = 128, activation = 'leaky_relu'),\n",
    "        tfl.Dense(units = 64, activation = 'leaky_relu'),\n",
    "        tfl.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate) #specify learning rate\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy',AUC])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.15.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.8 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.8/60.8 kB 802.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scipy) (2.1.3)\n",
      "Downloading scipy-1.15.2-cp311-cp311-win_amd64.whl (41.2 MB)\n",
      "   ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.6/41.2 MB 20.5 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 2.4/41.2 MB 30.7 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 4.0/41.2 MB 31.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 5.9/41.2 MB 34.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.7/41.2 MB 35.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 9.1/41.2 MB 34.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 10.7/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 12.3/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 14.0/41.2 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 15.7/41.2 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 17.2/41.2 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 18.9/41.2 MB 34.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 20.6/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 22.3/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 24.0/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 25.7/41.2 MB 36.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 27.4/41.2 MB 36.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 28.5/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 30.7/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.3/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 34.0/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 35.7/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.4/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.2/41.2 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.7/41.2 MB 36.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.2/41.2 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.2/41.2 MB 29.7 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.1 MB 6.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/11.1 MB 22.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.5/11.1 MB 28.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.4/11.1 MB 31.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 33.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.0/11.1 MB 34.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 36.4 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 301.8/301.8 kB ? eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytest\n",
      "  Downloading pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\huang\\appdata\\roaming\\python\\python311\\site-packages (from pytest) (0.4.6)\n",
      "Collecting iniconfig (from pytest)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\huang\\appdata\\roaming\\python\\python311\\site-packages (from pytest) (24.2)\n",
      "Collecting pluggy<2,>=1.5 (from pytest)\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Downloading pytest-8.3.5-py3-none-any.whl (343 kB)\n",
      "   ---------------------------------------- 0.0/343.6 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 81.9/343.6 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 343.6/343.6 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Installing collected packages: pluggy, iniconfig, pytest\n",
      "Successfully installed iniconfig-2.0.0 pluggy-1.5.0 pytest-8.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts py.test.exe and pytest.exe are installed in 'c:\\Users\\huang\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "   ---------------------------------------- 0.0/238.4 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 92.2/238.4 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 238.4/238.4 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy\n",
    "%pip install scikit-learn\n",
    "%pip install pytest\n",
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "rom = RandomOverSampler()\n",
    "X_res, y_res = rom.fit_resample(X, y) #oversample the data to balance the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 994us/step - accuracy: 0.6978 - auc: 0.5894 - loss: 23.8774 - learning_rate: 0.0030\n",
      "Epoch 2/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 988us/step - accuracy: 0.8950 - auc: 0.9418 - loss: 2.7945 - learning_rate: 0.0030\n",
      "Epoch 3/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 996us/step - accuracy: 0.9006 - auc: 0.9343 - loss: 2.5201 - learning_rate: 0.0030\n",
      "Epoch 4/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - accuracy: 0.9160 - auc: 0.9479 - loss: 4.0831 - learning_rate: 0.0030\n",
      "Epoch 5/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - accuracy: 0.9236 - auc: 0.9613 - loss: 1.7649 - learning_rate: 0.0030\n",
      "Epoch 6/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9282 - auc: 0.9680 - loss: 0.4148 - learning_rate: 3.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - accuracy: 0.9418 - auc: 0.9856 - loss: 0.1529 - learning_rate: 3.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9447 - auc: 0.9870 - loss: 0.1449 - learning_rate: 3.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - accuracy: 0.9445 - auc: 0.9875 - loss: 0.1423 - learning_rate: 3.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9451 - auc: 0.9876 - loss: 0.1412 - learning_rate: 3.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9501 - auc: 0.9901 - loss: 0.1248 - learning_rate: 3.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9537 - auc: 0.9915 - loss: 0.1141 - learning_rate: 3.0000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9558 - auc: 0.9926 - loss: 0.1068 - learning_rate: 3.0000e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9574 - auc: 0.9934 - loss: 0.1006 - learning_rate: 3.0000e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9602 - auc: 0.9940 - loss: 0.0950 - learning_rate: 3.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9683 - auc: 0.9963 - loss: 0.0781 - learning_rate: 3.0000e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - accuracy: 0.9694 - auc: 0.9967 - loss: 0.0749 - learning_rate: 3.0000e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - accuracy: 0.9704 - auc: 0.9969 - loss: 0.0720 - learning_rate: 3.0000e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - accuracy: 0.9708 - auc: 0.9970 - loss: 0.0703 - learning_rate: 3.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m17770/17770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - accuracy: 0.9715 - auc: 0.9972 - loss: 0.0680 - learning_rate: 3.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x186e3598c90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "step_decay = keras.callbacks.LearningRateScheduler(lambda epoch: learning_rate * 10**(- int (epoch/5)))\n",
    "model = create_model(learning_rate)\n",
    "model.fit(X_res, y_res, epochs = 20, callbacks = [step_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold: 0.99 bes F1: 0.7632311977715878\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_threshold = -1\n",
    "num_thresholds = 100\n",
    "\n",
    "thresholds = []\n",
    "scores = []\n",
    "best_F1 = 0\n",
    "\n",
    "for threshold in np.linspace(0,1,num_thresholds+1):\n",
    "    y_pred = model.predict(X, batch_size = len(y), verbose = 0)\n",
    "    y_pred = y_pred > threshold #apply threshold to predictions\n",
    "    F1 = fbeta_score(y,y_pred, beta = 1)\n",
    "    thresholds.append(threshold)\n",
    "    scores.append(F1)\n",
    "\n",
    "    if best_F1 < F1:\n",
    "        best_F1 = F1\n",
    "        best_threshold = threshold\n",
    "plt.plot(thresholds, scores)\n",
    "\n",
    "print('best threshold:', best_threshold, 'bes F1:', best_F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp311-cp311-win_amd64.whl.metadata (103 kB)\n",
      "     ---------------------------------------- 0.0/104.0 kB ? eta -:--:--\n",
      "     -------------------------------------  102.4/104.0 kB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 104.0/104.0 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\huang\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.1.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\huang\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\huang\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.6/8.1 MB 34.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.7/8.1 MB 39.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.6/8.1 MB 39.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.8/8.1 MB 41.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 36.8 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
      "   ---------------------------------------- 0.0/219.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 219.8/219.8 kB ? eta 0:00:00\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------------------------------- - 2.1/2.2 MB 45.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 35.3 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/72.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 72.0/72.0 kB ? eta 0:00:00\n",
      "Downloading pillow-11.1.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.4/2.6 MB 49.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 42.2 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.7/107.7 kB 6.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.1.0 pyparsing-3.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\huang\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
